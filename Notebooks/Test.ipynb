{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62c26a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from Prediction import*\n",
    "\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.models import ColumnDataSource\n",
    "from bokeh.palettes import Spectral3\n",
    "from bokeh.layouts import column\n",
    "output_file('Test_Preiction.html')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb2f00b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../Data/DrahiX_Data.csv', index_col=0, parse_dates=True)\n",
    "data = data.resample('15Min').mean()\n",
    "data = data.fillna(method='ffill')\n",
    "\n",
    "#Adding new features so that we can use the date and time in the model\n",
    "data['day of the week'] = data.index.dayofweek\n",
    "data['day of the year'] = data.index.dayofyear\n",
    "data['hour of the day'] = data.index.hour\n",
    "data['minute of the hour'] = data.index.minute\n",
    "data[\"TGBT\"] = data['T1']+data['T2']+data['T3']+data['T4']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eed32a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data, size):\n",
    "\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "\n",
    "    sequence_length = int(size)  \n",
    "\n",
    "    #Organizing the data and keeping only the columns that will be used in the model\n",
    "    features = ['day of the week','day of the year','hour of the day','minute of the hour', 'AirTemp','rh']\n",
    "    labels   = ['TGBT']\n",
    "    inputs   = features + labels\n",
    "    data = data[inputs]\n",
    "\n",
    "    num_features = len(features)\n",
    "    num_labels = len(labels)\n",
    "    num_inputs = num_features + num_labels\n",
    "\n",
    "    #Normalizing data between 1 and -1\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    \n",
    "    data_scaled = pd.DataFrame(scaler.fit_transform(data.values), columns=data.columns, index=data.index)\n",
    "    x_test_scaled = np.asarray(data_scaled[features])\n",
    "    y_test_scaled = np.asarray(data_scaled[labels])\n",
    "\n",
    "\n",
    "    sess=tf.Session()   \n",
    "    #First let's load meta graph and restore weights\n",
    "    saver = tf.train.import_meta_graph('Model'+str(size)+'/my_test_model-1000.meta')\n",
    "    saver.restore(sess,tf.train.latest_checkpoint('./Model'+str(size)+'/'))\n",
    "    graph = tf.get_default_graph()\n",
    "    x = graph.get_tensor_by_name(\"x:0\")\n",
    "    outputs = graph.get_tensor_by_name(\"op_to_restore:0\")\n",
    "\n",
    "    y_pred = sess.run(outputs, feed_dict={x: [x_test_scaled[:size]]})\n",
    "    y_test = y_pred.reshape(-1, num_labels)\n",
    "    scaler.fit(data[labels].iloc[:size])\n",
    "\n",
    "    DF = pd.DataFrame(scaler.inverse_transform(y_test), index=data.iloc[:size].iloc[0:sequence_length].index + pd.Timedelta(minutes=15*sequence_length), columns=labels)\n",
    "    \n",
    "    \n",
    "    for i in range(int(len(data)/size - 2)):\n",
    "            scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "            data_scaled = pd.DataFrame(scaler.fit_transform(data.iloc[size + size*i:2*size+size*i].values), columns=data.iloc[size + size*i:2*size+size*i].columns, index=data.iloc[size + size*i:2*size+size*i].index)\n",
    "            x_test_scaled = np.asarray(data_scaled[features])\n",
    "            y_test_scaled = np.asarray(data_scaled[labels])\n",
    "        \n",
    "            y_pred = sess.run(outputs, feed_dict={x: [x_test_scaled]})\n",
    "            y_test = y_pred.reshape(-1, num_labels)\n",
    "            scaler.fit(data[labels].iloc[size + size*i:2*size+size*i])\n",
    "    \n",
    "            result = pd.DataFrame(scaler.inverse_transform(y_test), index=data.iloc[size + size*i:2*size+size*i].iloc[0:sequence_length].index + pd.Timedelta(minutes=15*sequence_length), columns=labels)\n",
    "            DF = pd.concat([DF,result])\n",
    "        \n",
    "    return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a01bf35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./Model12/my_test_model-1000\n",
      "INFO:tensorflow:Restoring parameters from ./Model24/my_test_model-1000\n",
      "INFO:tensorflow:Restoring parameters from ./Model96/my_test_model-1000\n"
     ]
    }
   ],
   "source": [
    "result12 = predict(data, 12)\n",
    "result24 = predict(data, 24)\n",
    "result96 = predict(data, 96)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fcccded",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result12[\"TGBT\"] = (result12[\"TGBT\"] - data[\"TGBT\"].min())/(data[\"TGBT\"].max() - data[\"TGBT\"].min())\n",
    "result24[\"TGBT\"] = (result24[\"TGBT\"] - data[\"TGBT\"].min())/(data[\"TGBT\"].max() - data[\"TGBT\"].min())\n",
    "result96[\"TGBT\"] = (result96[\"TGBT\"] - data[\"TGBT\"].min())/(data[\"TGBT\"].max() - data[\"TGBT\"].min())\n",
    "data[\"TGBT\"] = (data[\"TGBT\"] - data[\"TGBT\"].min())/(data[\"TGBT\"].max() - data[\"TGBT\"].min())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7940672a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE : 0.006\n",
      "MAE : 0.050\n",
      "RMSE : 0.076\n",
      "\n",
      "MSE : 0.009\n",
      "MAE : 0.068\n",
      "RMSE : 0.096\n",
      "\n",
      "MSE : 0.009\n",
      "MAE : 0.069\n",
      "RMSE : 0.095\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "\n",
    "\n",
    "mse12 = mean_squared_error(result12[\"TGBT\"], data[\"TGBT\"].iloc[12:-1])\n",
    "rmse12 = sqrt(mse12)\n",
    "mae12 = mean_absolute_error(result12[\"TGBT\"], data[\"TGBT\"].iloc[12:-1])\n",
    "\n",
    "mse24 = mean_squared_error(result24[\"TGBT\"], data[\"TGBT\"].iloc[24:-1])\n",
    "rmse24 = sqrt(mse24)\n",
    "mae24 = mean_absolute_error(result24[\"TGBT\"], data[\"TGBT\"].iloc[24:-1])\n",
    "\n",
    "mse96 = mean_squared_error(result96[\"TGBT\"], data[\"TGBT\"].iloc[96:-1])\n",
    "rmse96 = sqrt(mse96)\n",
    "mae96 = mean_absolute_error(result96[\"TGBT\"], data[\"TGBT\"].iloc[96:-1])\n",
    "\n",
    "\n",
    "print('MSE : %.3f' % mse12)\n",
    "print('MAE : %.3f' % mae12)\n",
    "print('RMSE : %.3f' % rmse12)\n",
    "\n",
    "print('\\nMSE : %.3f' % mse24)\n",
    "print('MAE : %.3f' % mae24)\n",
    "print('RMSE : %.3f' % rmse24)\n",
    "\n",
    "print('\\nMSE : %.3f' % mse96)\n",
    "print('MAE : %.3f' % mae96)\n",
    "print('RMSE : %.3f' % rmse96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b656617",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n"
     ]
    }
   ],
   "source": [
    "\n",
    "p1 = figure(x_axis_type=\"datetime\",plot_width=1200)\n",
    "p1.title.text ='Model 3h'+'\\t\\t\\tMSE : %.3f' % mse12 + '\\t\\t\\tMAE : %.3f' % mae12 + '\\t\\t\\tRMSE : %.3f' % rmse12\n",
    "p1.line(x='Date and time (UTC)', y='TGBT', line_width=2, source=data, legend='Real Consumption')\n",
    "p1.line(x='Date and time (UTC)', y='TGBT', line_width=2, source=result12, color=Spectral3[2],legend='Prediction', alpha = 0.9)\n",
    "\n",
    "p2 = figure(x_axis_type=\"datetime\",plot_width=1200)\n",
    "p2.title.text ='Model 6h'+'\\t\\t\\tMSE : %.3f' % mse24 + '\\t\\t\\tMAE : %.3f' % mae24 + '\\t\\t\\tRMSE : %.3f' % rmse24\n",
    "p2.line(x='Date and time (UTC)', y='TGBT', line_width=2, source=data, legend='Real Consumption')\n",
    "p2.line(x='Date and time (UTC)', y='TGBT', line_width=2, source=result24, color=Spectral3[2],legend='Prediction',alpha = 0.9)\n",
    "\n",
    "p3 = figure(x_axis_type=\"datetime\",plot_width=1200)\n",
    "p3.title.text ='Model 24h'+'\\t\\t\\tMSE : %.3f' % mse96 + '\\t\\t\\tMAE : %.3f' % mae96 + '\\t\\t\\tRMSE : %.3f' % rmse96\n",
    "p3.line(x='Date and time (UTC)', y='TGBT', line_width=2, source=data, legend='Real Consumption')\n",
    "p3.line(x='Date and time (UTC)', y='TGBT', line_width=2, source=result96, color=Spectral3[2],legend='Prediction',alpha = 0.9)\n",
    "\n",
    "\n",
    "show(column(p1,p2,p3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bbae83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbfdcc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
