{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62c26a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.models import ColumnDataSource,Panel, Tabs\n",
    "from bokeh.palettes import Spectral3\n",
    "from bokeh.layouts import column, row, gridplot\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "\n",
    "output_file('Test_Prediction.html')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb2f00b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '.../Data/DrahiX_Data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-64dab379ab8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.../Data/DrahiX_Data.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'15Min'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ffill'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Telecom/venv/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Telecom/venv/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Telecom/venv/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Telecom/venv/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Telecom/venv/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '.../Data/DrahiX_Data.csv'"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('.../Data/DrahiX_Data.csv', index_col=0, parse_dates=True)\n",
    "data = data.resample('15Min').mean()\n",
    "data = data.fillna(method='ffill')\n",
    "data = data.iloc[int(len(data)*0.75):]\n",
    "\n",
    "\n",
    "Consumption = data['T1']+data['T2']+data['T3']+data['T4']\n",
    "\n",
    "df12 = data.iloc[:]\n",
    "df24 = data.iloc[:]\n",
    "df96 = data.iloc[:]\n",
    "\n",
    "df12.index = df12.index + pd.Timedelta(minutes=15*12)\n",
    "df24.index = df24.index + pd.Timedelta(minutes=15*24)\n",
    "df96.index = df96.index + pd.Timedelta(minutes=15*96)\n",
    "\n",
    "#Adding new features so that we can use the date and time in the model\n",
    "df12['day of the week'] = df12.index.dayofweek\n",
    "df12['day of the year'] = df12.index.dayofyear\n",
    "df12['hour of the day'] = df12.index.hour\n",
    "df12['minute of the hour'] = df12.index.minute\n",
    "df12[\"Consumption\"] = Consumption\n",
    "\n",
    "#Adding new features so that we can use the date and time in the model\n",
    "df24['day of the week'] = df24.index.dayofweek\n",
    "df24['day of the year'] = df24.index.dayofyear\n",
    "df24['hour of the day'] = df24.index.hour\n",
    "df24['minute of the hour'] = df24.index.minute\n",
    "df24[\"Consumption\"] = Consumption\n",
    "\n",
    "#Adding new features so that we can use the date and time in the model\n",
    "df96['day of the week'] = df96.index.dayofweek\n",
    "df96['day of the year'] = df96.index.dayofyear\n",
    "df96['hour of the day'] = df96.index.hour\n",
    "df96['minute of the hour'] = df96.index.minute\n",
    "df96[\"Consumption\"] = Consumption\n",
    "\n",
    "df12 = df12.iloc[:-12]\n",
    "df12 = df12.drop(columns = ['TGBT','T1','T2','T3','T4','T5','T6','T7'])\n",
    "\n",
    "df24 = df24.iloc[:-24]\n",
    "df24 = df24.drop(columns = ['TGBT','T1','T2','T3','T4','T5','T6','T7'])\n",
    "\n",
    "df96 = df96.iloc[:-96]\n",
    "df96 = df96.drop(columns = ['TGBT','T1','T2','T3','T4','T5','T6','T7'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f95447",
   "metadata": {},
   "source": [
    "# Test Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eed32a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data, size):\n",
    "\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "    sequence_length = int(size)  \n",
    "\n",
    "    #Organizing the data and keeping only the columns that will be used in the model\n",
    "    features = ['day of the week','day of the year','hour of the day', 'AirTemp','rh']\n",
    "    labels   = ['Consumption']\n",
    "    inputs   = features + labels\n",
    "    data = data[inputs]\n",
    "\n",
    "    num_features = len(features)\n",
    "    num_labels = len(labels)\n",
    "    num_inputs = num_features + num_labels\n",
    "\n",
    "    #Normalizing data between 1 and -1\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    \n",
    "    data_scaled = pd.DataFrame(scaler.fit_transform(data.values), columns=data.columns, index=data.index)\n",
    "    x_test_scaled = np.asarray(data_scaled[features])\n",
    "    y_test_scaled = np.asarray(data_scaled[labels])\n",
    "\n",
    "\n",
    "    sess=tf.Session()   \n",
    "    #First let's load meta graph and restore weights\n",
    "    saver = tf.train.import_meta_graph('Model'+str(size)+'/my_test_model-1000.meta')\n",
    "    saver.restore(sess,tf.train.latest_checkpoint('./Model'+str(size)+'/'))\n",
    "    graph = tf.get_default_graph()\n",
    "    x = graph.get_tensor_by_name(\"x:0\")\n",
    "    outputs = graph.get_tensor_by_name(\"op_to_restore:0\")\n",
    "\n",
    "    y_pred = sess.run(outputs, feed_dict={x: [x_test_scaled[:size]]})\n",
    "    y_test = y_pred.reshape(-1, num_labels)\n",
    "    scaler.fit(data[labels].iloc[:size])\n",
    "\n",
    "    DF = pd.DataFrame(scaler.inverse_transform(y_test), index=data.iloc[:size].index, columns=labels)\n",
    "    \n",
    "    \n",
    "    for i in range(int(len(data)/size) -2):\n",
    "            scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "            data_scaled = pd.DataFrame(scaler.fit_transform(data.iloc[size + size*i:2*size + size*i].values), columns=data.iloc[size + size*i:2*size + size*i].columns, index=data.iloc[size + size*i:2*size + size*i].index)\n",
    "            x_test_scaled = np.asarray(data_scaled[features])\n",
    "            y_test_scaled = np.asarray(data_scaled[labels])\n",
    "        \n",
    "            y_pred = sess.run(outputs, feed_dict={x: [x_test_scaled]})\n",
    "            y_test = y_pred.reshape(-1, num_labels)\n",
    "            scaler.fit(data[labels].iloc[size + size*i:2*size + size*i])\n",
    "    \n",
    "            result = pd.DataFrame(scaler.inverse_transform(y_test), index=data.iloc[size + size*i:2*size + size*i].iloc[0:sequence_length].index, columns=labels)\n",
    "            DF = pd.concat([DF,result])\n",
    "        \n",
    "    return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5a01bf35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./Model12/my_test_model-1000\n",
      "INFO:tensorflow:Restoring parameters from ./Model24/my_test_model-1000\n",
      "INFO:tensorflow:Restoring parameters from ./Model96/my_test_model-1000\n"
     ]
    }
   ],
   "source": [
    "result12 = predict(df12, 12)\n",
    "result24 = predict(df24, 24)\n",
    "result96 = predict(df96, 96)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "32509d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE : 6.952\n",
      "MAE : 1.717\n",
      "RMSE : 2.637\n",
      "\n",
      "MSE : 9.751\n",
      "MAE : 2.111\n",
      "RMSE : 3.123\n",
      "\n",
      "MSE : 10.766\n",
      "MAE : 2.420\n",
      "RMSE : 3.281\n"
     ]
    }
   ],
   "source": [
    "mse12 = mean_squared_error(result12[\"Consumption\"], df12[\"Consumption\"].iloc[:len(result12[\"Consumption\"])])\n",
    "rmse12 = sqrt(mse12)\n",
    "mae12 = mean_absolute_error(result12[\"Consumption\"], df12[\"Consumption\"].iloc[:len(result12[\"Consumption\"])])\n",
    "\n",
    "mse24 = mean_squared_error(result24[\"Consumption\"], df24[\"Consumption\"].iloc[:len(result24[\"Consumption\"])])\n",
    "rmse24 = sqrt(mse24)\n",
    "mae24 = mean_absolute_error(result24[\"Consumption\"], df24[\"Consumption\"].iloc[:len(result24[\"Consumption\"])])\n",
    "\n",
    "mse96 = mean_squared_error(result96[\"Consumption\"], df96[\"Consumption\"].iloc[:len(result96[\"Consumption\"])])\n",
    "rmse96 = sqrt(mse96)\n",
    "mae96 = mean_absolute_error(result96[\"Consumption\"], df96[\"Consumption\"].iloc[:len(result96[\"Consumption\"])])\n",
    "\n",
    "\n",
    "print('MSE : %.3f' % mse12)\n",
    "print('MAE : %.3f' % mae12)\n",
    "print('RMSE : %.3f' % rmse12)\n",
    "\n",
    "print('\\nMSE : %.3f' % mse24)\n",
    "print('MAE : %.3f' % mae24)\n",
    "print('RMSE : %.3f' % rmse24)\n",
    "\n",
    "print('\\nMSE : %.3f' % mse96)\n",
    "print('MAE : %.3f' % mae96)\n",
    "print('RMSE : %.3f' % rmse96)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8b656617",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n"
     ]
    }
   ],
   "source": [
    "\n",
    "p1 = figure(x_axis_type=\"datetime\",plot_width=1200)\n",
    "p1.title.text ='Model 3h'+'\\t\\t\\tMSE : %.3f' % mse12 + '\\t\\t\\tMAE : %.3f' % mae12 + '\\t\\t\\tRMSE : %.3f' % rmse12\n",
    "p1.line(x='Date and time (UTC)', y='Consumption', line_width=2, source=df12, legend='Real Consumption')\n",
    "p1.line(x='Date and time (UTC)', y='Consumption', line_width=2, source=result12, color=Spectral3[2],legend='Prediction', alpha = 0.8)\n",
    "\n",
    "p2 = figure(x_axis_type=\"datetime\",plot_width=1200)\n",
    "p2.title.text ='Model 6h'+'\\t\\t\\tMSE : %.3f' % mse24 + '\\t\\t\\tMAE : %.3f' % mae24 + '\\t\\t\\tRMSE : %.3f' % rmse24\n",
    "p2.line(x='Date and time (UTC)', y='Consumption', line_width=2, source=df24, legend='Real Consumption')\n",
    "p2.line(x='Date and time (UTC)', y='Consumption', line_width=2, source=result24, color=Spectral3[2],legend='Prediction',alpha = 0.8)\n",
    "\n",
    "p3 = figure(x_axis_type=\"datetime\",plot_width=1200)\n",
    "p3.title.text ='Model 24h'+'\\t\\t\\tMSE : %.3f' % mse96 + '\\t\\t\\tMAE : %.3f' % mae96 + '\\t\\t\\tRMSE : %.3f' % rmse96\n",
    "p3.line(x='Date and time (UTC)', y='Consumption', line_width=2, source=df96, legend='Real Consumption')\n",
    "p3.line(x='Date and time (UTC)', y='Consumption', line_width=2, source=result96, color=Spectral3[2],legend='Prediction',alpha = 0.8)\n",
    "\n",
    "\n",
    "show(column(p1,p2,p3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e2f242",
   "metadata": {},
   "source": [
    "# Test Time intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed324614",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_time(df12,df24,df96, time):\n",
    "\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "\n",
    "    #Organizing the data and keeping only the columns that will be used in the model\n",
    "    features = ['day of the week','day of the year','hour of the day', 'AirTemp','rh']\n",
    "    labels   = ['Consumption']\n",
    "    inputs   = features + labels\n",
    "    \n",
    "    df12 = df12[inputs]\n",
    "    df24 = df24[inputs]\n",
    "    df96 = df96[inputs]\n",
    "\n",
    "    num_features = len(features)\n",
    "    num_labels = len(labels)\n",
    "    num_inputs = num_features + num_labels\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "    \n",
    "    DF = []\n",
    "    \n",
    "    sess=tf.Session()  \n",
    "    saver = tf.train.import_meta_graph('Model12/my_test_model-1000.meta')\n",
    "    saver.restore(sess,tf.train.latest_checkpoint('./Model12/'))\n",
    "    graph = tf.get_default_graph()\n",
    "    x = graph.get_tensor_by_name(\"x:0\")\n",
    "    outputs = graph.get_tensor_by_name(\"op_to_restore:0\")\n",
    "    \n",
    "    for i in range(int((len(data)-96)/time)-3):\n",
    "        \n",
    "        data_scaled = pd.DataFrame(scaler.fit_transform(df12.iloc[84+i*time:96+i*time].values), columns=df12.iloc[84+i*time:96+i*time].columns, index=df12.iloc[84+i*time:96+i*time].index)\n",
    "        x_test_scaled = np.asarray(data_scaled[features])\n",
    "        y_test_scaled = np.asarray(data_scaled[labels])\n",
    "    \n",
    "        y_pred = sess.run(outputs, feed_dict={x: [x_test_scaled]})\n",
    "        y_test = y_pred.reshape(-1, num_labels)\n",
    "        scaler.fit(df12[labels].iloc[84+i*time:96+i*time])\n",
    "\n",
    "        DF += [pd.DataFrame(scaler.inverse_transform(y_test), index=df12.iloc[84+i*time:96+i*time].index, columns=labels).iloc[:min(12,time)]]\n",
    "    \n",
    "    \n",
    "    if time > 12 :\n",
    "        tf.compat.v1.reset_default_graph()\n",
    "        sess=tf.Session()  \n",
    "        saver = tf.train.import_meta_graph('Model24/my_test_model-1000.meta')\n",
    "        saver.restore(sess,tf.train.latest_checkpoint('./Model24/'))\n",
    "        graph = tf.get_default_graph()\n",
    "        x = graph.get_tensor_by_name(\"x:0\")\n",
    "        outputs = graph.get_tensor_by_name(\"op_to_restore:0\")\n",
    "\n",
    "        for i in range(int((len(data)-96)/time)-3):\n",
    "\n",
    "            data_scaled = pd.DataFrame(scaler.fit_transform(df24.iloc[72+i*time:96+i*time].values), columns=df24.iloc[72+i*time:96+i*time].columns, index=df24.iloc[72+i*time:96+i*time].index)\n",
    "            x_test_scaled = np.asarray(data_scaled[features])\n",
    "            y_test_scaled = np.asarray(data_scaled[labels])\n",
    "\n",
    "            y_pred = sess.run(outputs, feed_dict={x: [x_test_scaled]})\n",
    "            y_test = y_pred.reshape(-1, num_labels)\n",
    "            scaler.fit(df24[labels].iloc[72+i*time:96+i*time])\n",
    "\n",
    "            DF += [pd.DataFrame(scaler.inverse_transform(y_test), index=df24.iloc[72+i*time:96+i*time].index, columns=labels).iloc[12: min(24,time)]]\n",
    "    \n",
    "    if time > 24 :\n",
    "        tf.compat.v1.reset_default_graph()\n",
    "        sess=tf.Session()  \n",
    "        saver = tf.train.import_meta_graph('Model96/my_test_model-1000.meta')\n",
    "        saver.restore(sess,tf.train.latest_checkpoint('./Model96/'))\n",
    "        graph = tf.get_default_graph()\n",
    "        x = graph.get_tensor_by_name(\"x:0\")\n",
    "        outputs = graph.get_tensor_by_name(\"op_to_restore:0\")\n",
    "\n",
    "        for i in range(int((len(data)-96)/time)-3):\n",
    "\n",
    "            data_scaled = pd.DataFrame(scaler.fit_transform(df96.iloc[i*time:96+i*time].values), columns=df96.iloc[i*time:96+i*time].columns, index=df96.iloc[i*time:96+i*time].index)\n",
    "            x_test_scaled = np.asarray(data_scaled[features])\n",
    "            y_test_scaled = np.asarray(data_scaled[labels])\n",
    "\n",
    "            y_pred = sess.run(outputs, feed_dict={x: [x_test_scaled]})\n",
    "            y_test = y_pred.reshape(-1, num_labels)\n",
    "            scaler.fit(df96[labels].iloc[i*time:96+i*time])\n",
    "\n",
    "            DF += [pd.DataFrame(scaler.inverse_transform(y_test), index=df96.iloc[i*time:96+i*time].index, columns=labels).iloc[24: min(96,time)]]\n",
    "\n",
    "\n",
    "    \n",
    "    DF = pd.concat(DF)\n",
    "    DF = DF.sort_index()\n",
    "        \n",
    "    return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3bbae83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df12' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-7c174dd3176f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpredict_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf24\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf96\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df12' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "result = []\n",
    "for i in range(24):\n",
    "    result += [predict_time(df12,df24,df96, 4 + i*4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1e37f8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n"
     ]
    }
   ],
   "source": [
    "tab = []\n",
    "mse = []\n",
    "rmse = []\n",
    "mae = []\n",
    "\n",
    "for i in range(23):\n",
    "    mse += [mean_squared_error(result[i][\"TGBT\"], data[\"TGBT\"].iloc[96:len(result[i])+96])]\n",
    "    rmse += [sqrt(mse[i])]\n",
    "    mae += [mean_absolute_error(result[i][\"TGBT\"], data[\"TGBT\"].iloc[96:len(result[i])+96])]\n",
    "    \n",
    "    p1 = figure(x_axis_type=\"datetime\",plot_width=1500)\n",
    "    p1.title.text ='Model 3h'+'\\t\\t\\tMSE : %.3f' % mse[i] + '\\t\\t\\tMAE : %.3f' % mae[i] + '\\t\\t\\tRMSE : %.3f' % rmse[i]\n",
    "    p1.line(x='Date and time (UTC)', y='TGBT', line_width=2, source=data.iloc[96:len(result[i])+96], legend='Real Consumption')\n",
    "    p1.line(x='Date and time (UTC)', y='TGBT', line_width=2, source=result[i], color=Spectral3[2],legend='Prediction', alpha = 0.8)\n",
    "    tab += [Panel(child=p1, title=str(i+1))]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "661eee49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BokehUserWarning: ColumnDataSource's columns must be of the same length. Current lengths: ('x', 24), ('y', 23)\n",
      "BokehUserWarning: ColumnDataSource's columns must be of the same length. Current lengths: ('x', 24), ('y', 23)\n",
      "BokehUserWarning: ColumnDataSource's columns must be of the same length. Current lengths: ('x', 24), ('y', 23)\n"
     ]
    }
   ],
   "source": [
    "p1 = figure(plot_width=500, plot_height= 300)\n",
    "p1.title.text ='MSE'\n",
    "p1.line(range(25)[1:], mse, line_width=2)\n",
    "tab1 = [Panel(child=p1, title=\"MSE\")]\n",
    "              \n",
    "p2 = figure(plot_width=500, plot_height= 300)\n",
    "p2.title.text ='RMSE'\n",
    "p2.line(range(25)[1:], rmse, line_width=2)\n",
    "tab2 = [Panel(child=p2, title=\"RMSE\")]\n",
    "              \n",
    "p3 = figure(plot_width=500, plot_height= 300)\n",
    "p3.title.text ='MAE'\n",
    "p3.line(range(25)[1:], mae, line_width=2)\n",
    "tab3 = [Panel(child=p3, title=\"MAE\")]\n",
    "\n",
    "show(column(Tabs(tabs=tab),row(p1,p2,p3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5106bc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
